apiVersion: actions.github.com/v1alpha1
kind: AutoscalingRunnerSet
metadata:
  name: nprd-autoscale-runners
  namespace: managed-cicd
  labels:
    # Version label (as per official documentation)
    # Documentation mentions app.kubernetes.io/version=<chart version> for pods
    # Trying same format for AutoscalingRunnerSet
    app.kubernetes.io/version: "0.13.1"
  annotations:
    # NOTE: Official troubleshooting docs don't mention version annotations
    # Version may be managed via Helm chart, not manual annotations
    # Keeping minimal annotations for now
spec:
  # Organization-level runner scale set
  # Available to all repositories in the organization
  # Runners are assigned to a runner group for access control
  githubConfigUrl: https://github.com/DataKnifeAI
  
  # Authentication secret (REQUIRED)
  # Secret created by Terraform with GitHub App credentials
  githubConfigSecret: github-app-secret
  
  # Runner group name (must exist in GitHub org settings)
  # Create this group in: https://github.com/organizations/DataKnifeAI/settings/actions/runners
  # Configure it to allow "All repositories" or select specific repos
  # IMPORTANT: For PUBLIC repositories, you MUST enable "Allow public repositories" flag
  # in the runner group settings, otherwise workflows will remain queued!
  # Go to: https://github.com/organizations/DataKnifeAI/settings/actions/runner-groups
  # Click on your group → Enable "Allow public repositories" → Save
  # NOTE: Runner group must exist BEFORE creating this resource
  runnerGroup: NRPD Auto Scale
  
  # Runner scale set name (used in GitHub)
  # IMPORTANT: ARC runner scale sets expose ONLY this name as a label
  # Per official docs: https://docs.github.com/en/actions/tutorials/use-actions-runner-controller/use-arc-in-a-workflow
  # "You cannot use additional labels to target runners created by ARC.
  # You can only use the installation name...or runnerScaleSetName field.
  # These are used as the 'single label' to use as your runs-on target."
  # Workflows must use: runs-on: <runnerScaleSetName>
  # This matches workflow: runs-on: self-hosted
  runnerScaleSetName: self-hosted
  
  # Maximum number of runners that can be created
  maxRunners: 10
  
  # Minimum number of runners to maintain
  # CRITICAL: This is a workaround for GitHub issue #4000:
  # https://github.com/actions/actions-runner-controller/issues/4000
  # "Runners are being removed for being idle before its job has had a chance to be assigned to it"
  #
  # The issue: Ephemeral runners are killed after ~5 seconds if idle, before jobs can be assigned.
  # The workaround: Set minRunners > 0 to keep runners alive and idle, allowing jobs to be assigned immediately.
  #
  # IMPORTANT: This requires the "Allow public repositories" flag to be enabled in the runner group
  # settings, otherwise public repos can't use these runners and the endless loop will continue.
  # Enable it at: https://github.com/organizations/DataKnifeAI/settings/actions/runner-groups
  # Click "NRPD Auto Scale" → Enable "Allow public repositories" → Save
  #
  # Without this flag, jobs can't be assigned to runners, causing them to exit, which triggers
  # the listener to create more runners, creating an endless loop.
  minRunners: 2
  
  # Container spec for the runner pods
  template:
    spec:
      # CRITICAL FIX: Set restartPolicy to Never for ephemeral runners
      # With Always (default), Kubernetes restarts completed pods, causing endless loop
      # Ephemeral runners should exit cleanly and NOT restart
      # This is the KEY missing configuration causing the endless loop!
      restartPolicy: Never
      
      containers:
      - name: runner
        image: ghcr.io/actions/actions-runner:latest
        resources:
          # Increased requests to prevent premature exits
          # Low resource requests can cause pods to exit prematurely
          requests:
            cpu: 500m  # Increased from 100m to prevent resource starvation
            memory: 512Mi  # Increased from 128Mi to prevent OOM kills
          limits:
            cpu: "2"  # Use normalized format to match Kubernetes (2000m = 2)
            memory: 4Gi
  
  # Official ARC uses ephemeral runners by default
  # Ephemeral runners automatically clean up after job completion
  # This is built-in behavior - there's no ephemeral field to configure
  # With minRunners: 2, runners stay alive between jobs (allowing immediate job assignment)
  # but still clean up after completing each job, maintaining ephemeral behavior per job
  #
  # See GitHub issue #4000 for details on why minRunners > 0 is needed:
  # https://github.com/actions/actions-runner-controller/issues/4000
